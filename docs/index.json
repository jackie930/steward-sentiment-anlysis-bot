[{"uri":"/01introduction.html","title":" 背景介绍","tags":[],"description":"","content":"电商评论数据是指各大电商平台商品详情页面该商品的商品评价信息。如图所示，顾客印象、满意度、买家信息、评论信息、晒图链接、购买款式、评价时间等。除了图上显示的还有，购买时间，商品价格，标题、副标题、活动信息等其实只要有需求都能被采集。\n那么这些信息被采集的价值何在呢？\n  根据电商评论信息，做产品的电商渠道舆论分析，根据分析结果来优化品牌服务和产品迭代\n  根据电商平台的评论数，推测市场占比的市占数据\n  以上两点不管是对于品牌方来说还是对于市场分析调研来说都具有重要的价值。\n"},{"uri":"/01introduction/100algorithm.html","title":"1.1 算法概述","tags":[],"description":"","content":"使用场景  Understand trends: to understand what people are talking about, things they like or things they do not like about. Improve your products from users feedbacks. To follow up with your user about the product that they don’t like and further to understand the problem. To decrease return rate, re-stocking fees is one of the big expenses for e-commerce to succeed or even stay alive.  使用方法  关键词抽取 情感分析 实体提取  "},{"uri":"/01introduction/200data.html","title":"1.2 数据集","tags":[],"description":"","content":"dataset： https://nijianmo.github.io/amazon/index.html\ncontains：\n  data\n reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B asin - ID of the product, e.g. 0000013714 reviewerName - name of the reviewer vote - helpful votes of the review style - a disctionary of the product metadata, e.g., \u0026ldquo;Format\u0026rdquo; is \u0026ldquo;Hardcover\u0026rdquo; reviewText - text of the review overall - rating of the product summary - summary of the review unixReviewTime - time of the review (unix time) reviewTime - time of the review (raw) image - images that users post after they have received the product    metadata\n asin - ID of the product, e.g. 0000031852 title - name of the product feature - bullet-point format features of the product description - description of the product price - price in US dollars (at time of crawl) imageURL - url of the product image imageURL - url of the high resolution product image related - related products (also bought, also viewed, bought together, buy after viewing) salesRank - sales rank information brand - brand name categories - list of categories the product belongs to tech1 - the first technical detail table of the product tech2 - the second technical detail table of the product similar - similar product table    "},{"uri":"/02comprehend.html","title":"基于Amazon Comprehend的电商评论分析","tags":[],"description":"","content":"在本分步教程中，您将学习如何使用 Amazon Comprehend 分析文本并从中获取见解。\nAmazon Comprehend 是一种自然语言处理 (NLP) 服务，它使用机器学习来查找文本中的见解和关系。 Amazon Comprehend 使用机器学习来帮助您发现非结构化数据中的见解和关系。该服务识别文本的语言；提取关键短语、地点、人物、品牌或事件；了解文本的积极或消极程度；使用标记化和词性分析文本；并按主题自动组织文本文件的集合。\n在本教程场景中，您正在计划旅行并希望找到有用的旅行书籍。您选择了一本书，现在想要使用 Amazon Comprehend 处理一些评论，以了解其他客户是否认为这本书有价值。\n在本教程中，您将学习如何：\n 登录 Amazon Comprehend 控制台 对三个客户评论运行内置文本分析 探索来自文本分析的见解，包括情绪、实体、关键短语、语言和语法 使用情感分析结果进行决策  Step 1. Get started with Amazon Comprehend 首先，在 AWS 管理控制台中登录 Amazon Comprehend。 （或者，在 AWS 管理控制台中，搜索 Comprehend，然后选择启动 Amazon Comprehend。）\n左侧导航窗格中，选择实时分析并向下滚动到输入文本。对于分析类型，选择内置。 Amazon Comprehend 控制台使您能够分析长达 5,000 个字符的文档内容。结果显示在控制台中，以便您可以查看分析。在本教程中，您将使用内置分析。要了解有关使用 Comprehend 端点的自定义实时分析的更多信息，请参阅为自定义分类创建端点。\nStep 2. Analyze text with Amazon Comprehend Insights 在Input文本框中，复制并粘贴下面的文本，然后选择Analyze\nI just wanted to find some really cool new places such as Seattle in November. I’ve never visited before but no luck here. Some of these suggestions are just terrible… I had to laugh! Most suggestions were just your typical big cities, restaurants and bars. Nothing off the beaten path here. I don’t want to go these places for fun. Totally not worth getting this. Step 3. 查看结果 实体抽取结果：\n关键短语：\n情感分类 "},{"uri":"/03sagemaker.html","title":"基于Amazon SageMaker的电商评论分析","tags":[],"description":"","content":""},{"uri":"/03sagemaker/0300prepare.html","title":"环境准备","tags":[],"description":"","content":"Amazon SageMaker 环境准备\n要完成本workshop操作步骤，您需要准备一台Amazon SageMaker笔记本实例：\n实例类型： p3.xlarge 存储: 150G\n打开sagemaker，点击右上角的create notebook instance 填入如下配置信息，然后点击create notebook instance 然后可以看到，提示笔记本正在创建中 等待一会儿，创建完成，点击create notebook instance\n"},{"uri":"/03sagemaker/0301sentiment.html","title":" 评论情感分析： bert-sentiment-analysis模型实验","tags":[],"description":"","content":"首先下载代码\ncd SageMaker git clone https://github.com/jackie930/steward-sentiment-anlysis-bot 然后部署一个预置的endpoint\n#sin endpoint_ecr_image=\u0026#34;204427409592.dkr.ecr.cn-northwest-1.amazonaws.com.cn/sentiment-analyisis-endpoint\u0026#34; python create_endpoint.py \\ --endpoint_ecr_image_path ${endpoint_ecr_image} \\ --endpoint_name \u0026#39;bert-sentiment-anylsis\u0026#39; \\ --instance_type \u0026#34;ml.m5.xlarge\u0026#34; 在部署结束后，看到SageMaker控制台生成了对应的endpoint,可以使用如下客户端代码测试调用\nfrom boto3.session import Session import json txt = \u0026#34;这瓶酸奶很好喝！\u0026#34; data={\u0026#34;data\u0026#34;: txt} session = Session() runtime = session.client(\u0026#34;runtime.sagemaker\u0026#34;) response = runtime.invoke_endpoint( EndpointName=\u0026#39;bert-sentiment-anylsis\u0026#39;, ContentType=\u0026#34;application/json\u0026#34;, Body=json.dumps(data), ) result = json.loads(response[\u0026#34;Body\u0026#34;].read()) print (result) 训练部分可以参考github中readme部分。\n"},{"uri":"/03sagemaker/0302ner.html","title":" 评论实体抽取（中文）： bert-ner","tags":[],"description":"","content":"打开sagemaker notebook，运行如下代码\nfrom sagemaker.huggingface import HuggingFaceModel import sagemaker role = sagemaker.get_execution_role() # Hub Model configuration. https://huggingface.co/models hub = { 'HF_MODEL_ID':'uer/roberta-base-finetuned-cluener2020-chinese', 'HF_TASK':'token-classification' } # create Hugging Face Model Class huggingface_model = HuggingFaceModel( transformers_version='4.6.1', pytorch_version='1.7.1', py_version='py36', env=hub, role=role, ) # deploy model to SageMaker Inference predictor = huggingface_model.deploy( initial_instance_count=1, # number of instances instance_type='ml.m5.xlarge' # ec2 instance type ) 可以看见，endpoint创建中\n大约需要5-10分钟进行创建，创建完成后，运行\npredictor.predict({'inputs': \u0026quot;这款产品的性价比很高,是雅诗兰黛出品的!非常适合深圳\u0026quot;}) 可以看到结果如下：\n[{'word': '雅', 'score': 0.8944573402404785, 'entity': 'B-company', 'index': 13, 'start': 12, 'end': 13}, {'word': '诗', 'score': 0.876692533493042, 'entity': 'I-company', 'index': 14, 'start': 13, 'end': 14}, {'word': '兰', 'score': 0.8576887845993042, 'entity': 'I-company', 'index': 15, 'start': 14, 'end': 15}, {'word': '黛', 'score': 0.8687329292297363, 'entity': 'I-company', 'index': 16, 'start': 15, 'end': 16}, {'word': '深', 'score': 0.6078625917434692, 'entity': 'B-address', 'index': 25, 'start': 24, 'end': 25}, {'word': '圳', 'score': 0.5282930135726929, 'entity': 'I-address', 'index': 26, 'start': 25, 'end': 26}] "},{"uri":"/03sagemaker/0303keword.html","title":" 评论关键词/关键句抽取： texkrank模型实验","tags":[],"description":"","content":"TextRank算法可以用来从文本中提取关键词和摘要（重要的句子）。TextRank4ZH是针对中文文本的TextRank算法的python算法实现。\n原理 TextRank的详细原理请参考：\n Mihalcea R, Tarau P. TextRank: Bringing order into texts[C]. Association for Computational Linguistics, 2004.\n 关于TextRank4ZH的原理和使用介绍：使用TextRank算法为文本生成关键字和摘要\n关键词提取 将原文本拆分为句子，在每个句子中过滤掉停用词（可选），并只保留指定词性的单词（可选）。由此可以得到句子的集合和单词的集合。\n每个单词作为pagerank中的一个节点。设定窗口大小为k，假设一个句子依次由下面的单词组成：\nw1, w2, w3, w4, w5, ..., wn w1, w2, ..., wk、w2, w3, ...,wk+1、w3, w4, ...,wk+2等都是一个窗口。在一个窗口中的任两个单词对应的节点之间存在一个无向无权的边。\n基于上面构成图，可以计算出每个单词节点的重要性。最重要的若干单词可以作为关键词。\n关键短语提取 参照关键词提取提取出若干关键词。若原文本中存在若干个关键词相邻的情况，那么这些关键词可以构成一个关键词组。\n例如，在一篇介绍支持向量机的文章中，可以找到关键词支持、向量、机，通过关键词组提取，可以得到支持向量机。\n摘要生成 将每个句子看成图中的一个节点，若两个句子之间有相似性，认为对应的两个节点之间有一个无向有权边，权值是相似度。\n通过pagerank算法计算得到的重要性最高的若干句子可以当作摘要。\n示例 见example、test。\n使用说明 类TextRank4Keyword、TextRank4Sentence在处理一段文本时会将文本拆分成4种格式：\n sentences：由句子组成的列表。 words_no_filter：对sentences中每个句子分词而得到的两级列表。 words_no_stop_words：去掉words_no_filter中的停止词而得到的二维列表。 words_all_filters：保留words_no_stop_words中指定词性的单词而得到的二维列表。  本地部署 server\ngit clone https://github.com/jackie930/TextRank4ZH.git cd TextRank4ZH/apps/text_summry_endpoint Deploy endpoint on SageMaker #sin #endpoint_ecr_image=\u0026#34;847380964353.dkr.ecr.ap-southeast-1.amazonaws.com/textrank\u0026#34; #ningxia endpoint_ecr_image=\u0026#34;251885400447.dkr.ecr.cn-northwest-1.amazonaws.com.cn/textrank\u0026#34; python create_endpoint.py \\ --endpoint_ecr_image_path ${endpoint_ecr_image} \\ --endpoint_name \u0026#39;textrank\u0026#39; \\ --instance_type \u0026#34;ml.t2.medium\u0026#34; 在部署结束后，看到SageMaker控制台生成了对应的endpoint,可以使用如下客户端代码测试调用\nfrom boto3.session import Session import json data={\u0026#34;data\u0026#34;: \u0026#34;《半導體》Q1展望保守，世界垂淚2019/02/11 10:28時報資訊【時報記者沈培華台北報導】世界先進 (5347) 去年營運創歷史新高，每股純益達3.72元。但對今年首季展望保守，預計營收將比上季高點減近一成。世界先進於封關前股價拉高，今早則是開平走低。世界先進於年前台股封關後舉行法說會公布財報。公司去年營運表現亮麗，營收與獲利同創歷史新高紀錄。2018年全年營收289.28億元，年增16.1%，毛利率35.2%，拉升3.2個百分點，稅後淨利61.66億元，年增36.9%，營收與獲利同創歷史新高，每股純益3.72元。董事會通過去年度擬配發現金股利3.2元。展望第一季，受到客戶進入庫存調整，公司預期，本季營收估在67億至71億元，將季減8%至13%，毛利率將約34.5%至36.5%。此外，因應客戶需求，世界先進決定斥資2.36億美元，收購格芯新加坡8吋晶圓廠。世界先進於年前宣布，將購買格芯位於新加坡Tampines的8吋晶圓3E廠房、廠務設施、機器設備及微機電(MEMS)智財權與業務，交易總金額2.36億美元，交割日訂108年12月31日。格芯晶圓3E廠現有月產能3.5萬片8吋晶圓，世界先進每年將可增加超過40萬片8吋晶圓產能，增進公司明年起業績成長動能。TOP關閉\u0026#34;} session = Session() runtime = session.client(\u0026#34;runtime.sagemaker\u0026#34;) response = runtime.invoke_endpoint( EndpointName=\u0026#39;textrank\u0026#39;, ContentType=\u0026#34;application/json\u0026#34;, Body=json.dumps(data), ) result = json.loads(response[\u0026#34;Body\u0026#34;].read()) print (result) 结果如下\n{\u0026#34;res\u0026#34;: {\u0026#34;关键词列表\u0026#34;: [\u0026#34;公司\u0026#34;, \u0026#34;後\u0026#34;, \u0026#34;於\u0026#34;, \u0026#34;客戶\u0026#34;, \u0026#34;世界\u0026#34;, \u0026#34;會\u0026#34;, \u0026#34;歷史\u0026#34;, \u0026#34;展望\u0026#34;, \u0026#34;高點\u0026#34;, \u0026#34;定斥\u0026#34;, \u0026#34;保守\u0026#34;, \u0026#34;去年\u0026#34;, \u0026#34;年度\u0026#34;, \u0026#34;金\u0026#34;, \u0026#34;廠務\u0026#34;, \u0026#34;智\u0026#34;, \u0026#34;時報\u0026#34;, \u0026#34;擬配\u0026#34;, \u0026#34;發現\u0026#34;, \u0026#34;公布\u0026#34;], \u0026#34;关键词权重\u0026#34;: [0.021830182644348436, 0.021326461850579626, 0.021079603384026722, 0.01895223347929955, 0.01805834763586865, 0.015857085161081398, 0.014919166963726964, 0.01471938511506705, 0.014620888893926702, 0.014620888893926702, 0.014001573075273081, 0.013746893722718052, 0.011987812728358822, 0.011987812728358822, 0.011643071195825557, 0.011643071195825555, 0.011533578138425806, 0.011474480918306437, 0.011474480918306437, 0.011389711378308801], \u0026#34;摘要列表\u0026#34;: [\u0026#34;《半導體》Q1展望保守，世界垂淚2019/02/11 10:28時報資訊【時報記者沈培華台北報導】世界先進 (5347) 去年營運創歷史新高，每股純益達3.72元\u0026#34;, \u0026#34;世界先進於年前宣布，將購買格芯位於新加坡Tampines的8吋晶圓3E廠房、廠務設施、機器設備及微機電(MEMS)智財權與業務，交易總金額2.36億美元，交割日訂108年12月31日\u0026#34;, \u0026#34;格芯晶圓3E廠現有月產能3.5萬片8吋晶圓，世界先進每年將可增加超過40萬片8吋晶圓產能，增進公司明年起業績成長動能\u0026#34;], \u0026#34;摘要位置index\u0026#34;: [0, 9, 10], \u0026#34;摘要权重\u0026#34;: [0.1061431564717524, 0.10339832449272994, 0.09211266281495177]}} "},{"uri":"/","title":"AWS电商评论分析动手训练营","tags":[],"description":"","content":"Author\n JUNYI LIU (AWS GCR Applied Scientist)  概述 本次workshop分为几个部分\n 背景介绍- 电商评论分析 基于Amazon Comprehend的电商评论分析 基于Amazon SageMaker的电商评论分析  评论数据情感分析 评论数据主题提取 评论数据关键词提取 长评摘要    本次 workshop 前提 本次 workshop 建议在 宁夏 Region 使用。为了演示方便，所以本 workshop 所有的演示都会以宁夏 Region 为例。\n"},{"uri":"/categories.html","title":"Categories","tags":[],"description":"","content":""},{"uri":"/tags.html","title":"Tags","tags":[],"description":"","content":""}]